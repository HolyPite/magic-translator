import unicodedata

def transcrire_phonetique(texte_latin):
    """
    Transcripteur phonÃ©tique : Groupe les sons complexes avant de traduire.
    Cela donne un texte plus court et dense, plus proche d'une prononciation.
    """
    # 1. Normalisation (Majuscules, sans accents)
    texte_normalise = ''.join(
        c for c in unicodedata.normalize('NFKD', texte_latin).upper()
        if not unicodedata.combining(c)
    )

    # 2. DÃ©finition et application des sons complexes (L'ordre est important : les plus longs d'abord)
    # Utilisez des caractÃ¨res phÃ©niciens directement, car l'Ã©tape de remplacement gÃ©rera cela.
    PHONEMES = [
        ("EAU", "ð¤"), # EAU -> O (Ayin - pour changer du O simple)
        ("AU", "ð¤"),  # AU -> O (Ayin)
        ("CH", "ð¤”"), # CH -> Å in (Comme SH)
        ("SH", "ð¤”"),
        ("PH", "ð¤"), # PH -> PÄ“ (F)
        ("TH", "ð¤ˆ"), # TH -> á¹¬Ä“t
        ("QU", "ð¤’"), # QU -> QÅp
        ("OU", "ð¤…"), # OU -> Waw (Son W/U)
        ("OI", "ð¤…"), # OI -> Waw (Son Wa)
        ("AN", "ð¤"),  # Nasale -> Nun
        ("EN", "ð¤"),  # Nasale -> Nun
        ("ON", "ð¤Œ"),  # Nasale -> Mem (Son M sourd)
        ("IN", "ð¤‰"),  # Nasale -> Yod
        ("TT", "ð¤ˆ") # Du script original
    ]

    # Tri par longueur dÃ©croissante pour traiter les plus longs en premier
    PHONEMES.sort(key=lambda x: len(x[0]), reverse=True)

    texte_intermediaire = texte_normalise
    for latin_seq, phen_char in PHONEMES:
        texte_intermediaire = texte_intermediaire.replace(latin_seq, phen_char)
    
    # 3. Mapping standard pour les lettres restantes
    MAPPING_SINGLE_CHARS = {
        'A': 'ð¤€', 'B': 'ð¤', 'C': 'ð¤‚', 'D': 'ð¤ƒ', 'E': 'ð¤„',
        'F': 'ð¤…', 'G': 'ð¤‚', 'H': 'ð¤‡', 'I': 'ð¤‰', 'J': 'ð¤‰',
        'K': 'ð¤Š', 'L': 'ð¤‹', 'M': 'ð¤Œ', 'N': 'ð¤', 'O': 'ð¤',
        'P': 'ð¤', 'Q': 'ð¤’', 'R': 'ð¤“', 'S': 'ð¤”', 'T': 'ð¤•',
        'U': 'ð¤…', 'V': 'ð¤…', 'W': 'ð¤…', 'X': 'ð¤”', 'Y': 'ð¤‰',
        'Z': 'ð¤”'
    }

    transcription_avec_doubles = []
    for char in texte_intermediaire:
        # Si c'est dÃ©jÃ  un caractÃ¨re phÃ©nicien (mis par PHONEMES), on le garde.
        # Sinon, on le mappe avec les caractÃ¨res simples.
        # La plage Unicode pour le phÃ©nicien est U+10900 Ã  U+1091F
        if ord(char) >= 0x10900 and ord(char) <= 0x1091F: 
            transcription_avec_doubles.append(char)
        else:
            transcription_avec_doubles.append(MAPPING_SINGLE_CHARS.get(char, char))

    transcription_finale = "".join(transcription_avec_doubles)

    # 4. DÃ©doublement : suppression des caractÃ¨res phÃ©niciens consÃ©cutifs identiques
    resultat_dedouble = []
    dernier_char_phenicien = None
    
    for char in transcription_finale:
        # VÃ©rifier si le caractÃ¨re actuel est un caractÃ¨re phÃ©nicien
        est_phenicien = (ord(char) >= 0x10900 and ord(char) <= 0x1091F)
        
        if est_phenicien:
            # Si le caractÃ¨re phÃ©nicien actuel est diffÃ©rent du prÃ©cÃ©dent phÃ©nicien, on l'ajoute
            if char != dernier_char_phenicien:
                resultat_dedouble.append(char)
            # Mettre Ã  jour le dernier caractÃ¨re phÃ©nicien vu
            dernier_char_phenicien = char
        else:
            # Si ce n'est pas un caractÃ¨re phÃ©nicien (espace, ponctuation), on l'ajoute
            # et on rÃ©initialise dernier_char_phenicien (car il ne faut pas dÃ©doubler
            # aprÃ¨s une coupure comme un espace).
            resultat_dedouble.append(char)
            dernier_char_phenicien = None # RÃ©initialiser le compteur de sÃ©quence
            
    return "".join(resultat_dedouble)

# Test
if __name__ == "__main__":
    phrases = [
        "Chanter la chanson", 
        "Pharaon", 
        "Oiseau", 
        "Boule de feu", 
        "EAU chaude",
        "ATTENTION Cible",
        "Un chat", # Test "AN"
        "Bon vent" # Test "ON"
    ]
    for p in phrases:
        print(f"{p} -> {transcrire_phonetique(p)}")